[![Review Assignment Due Date](https://classroom.github.com/assets/deadline-readme-button-24ddc0f5d75046c5622901739e7c5dd533143b0c8e959d652212380cedb1ea36.svg)](https://classroom.github.com/a/LaCb-Cwa)
# Final Project
For instructions and submission date see the Course Policy file in the course website.

# Problem Statement
Toxicity in in-game chat has significantly impacted esports titles, affecting both players and the industry as a whole. The presence of toxic behaviour in the form of abusive language, harassment, hate speech, and disrespect creates a hostile environment, leading to a negative player experience. This negativity can result in reduced player retention as individuals may be discouraged from enjoying the game. Moreover, toxicity can undermine the competitive integrity of esports by promoting cheating, exploiting, and unsportsmanlike conduct, compromising fair play and the overall integrity of competitive events. Beyond the gameplay itself, toxicity in in-game chat also takes a toll on players’ mental well-being. Constant exposure to toxic behaviour can contribute to increased stress, anxiety, and even depression, posing serious psychological risks. This not only affects individual players but also impacts the overall community health of the esports ecosystem. Toxicity creates divisions, toxic rivalries, and an unwelcoming atmosphere, hindering the growth and inclusivity of the esports community. In addition to the player-level implications, toxicity in esports titles also has consequences for brand reputation. Negative publicity surrounding toxic behaviour can tarnish the games’ reputations and the brands associated with them. Potential players may be discouraged from joining the esports community, and sponsors may hesitate to support events and teams, impacting the industry's growth potential.

# Dataset
We have found a dataset of dual annotated text messages from the Massive Online Battle Arena (MOBA) called DoTA2(CONDA: a CONtextual Dual-Annotated dataset for in-game toxicity understanding and detection). The dataset has 45,000 utterances from 12000 conversations. These conversations belong to chat logs of 1900 matches.
